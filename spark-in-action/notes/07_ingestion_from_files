-----------------------------------------------------------------------
|  CHAPTER 7 - INGESTION FROM FILES                                   |
-----------------------------------------------------------------------

- Common Behavior of Parsers

    - We can use regexes in the file paths.  For instance, if we use 'a*' in the path,
        all files starting with 'a' will be ingested.

    - Options are not case-sensitive.  So 'multiline' and 'multiLine' are the same thing.



- Complex Ingestion From CSV

    - CSV has been around forever, and it has many variations:

        - the separators are not always commas
        - some records span multiple lines
        - there are various ways of escaping the separator


    - Here is the csv load we are using for this exercise:

        df = spark.read.format("csv") \
                  .option("header", "true") \
                  .option("multiline", True) \             # Some records split over multiple lines
                  .option("sep", ";") \                    # Separator is ;
                  .option("quote", "*") \                  # Escape character is *
                  .option("dateFormat", "MM/dd/yyyy") \    # Data matches MM/dd/yyyy format
                  .option("inferSchema", True) \
                  .load(CSV_FILE_PATH)


    - Note that even though Spark is inferring the schema, we still need to give it a hint
        about the date format so that the dates get parsed correctly.



- Ingesting a CSV with a Known Schema

    - We can infer the schema, but if we know the schema ahead of time, it can be useful
        to specify the datatypes by telling Spark what schema to use.


    - Here we create the schema:

        schema = StructType([StructField('id', IntegerType(), False),
                     StructField('authorId', IntegerType(), True),
                     StructField('bookTitle', IntegerType(), False),
                     StructField('releaseDate', DateType(), True),
                     StructField('url', StringType(), False)])


    - A StructField object comprises three fields, name (a string), dataType (a DataType) 
        and nullable (a bool).


    - Then we can use the schema when loading the csv:

        df = spark.read.format("csv") \
                  .option("header", True) \
                  .option("multiline", True) \
                  .option("sep", ";") \
                  .option("dateFormat", "MM/dd/yyyy") \
                  .option("quote", "*") \
                  .schema(schema) \
                  .load(absolute_file_path)



- Ingesting a JSON File

    - With the popularity of REST, JSON has become an extremely popular data exchange 
        format.  It is easier to read, less verbose, and has fewer constraints than XML.


    - There is a subformat of JSON called 'JSON Lines'.  JSON Lines stores a record on
        one line, which makes for easy parsing and readability.


    - Loading this format is very simple:

        df = spark.read.format("json") \
                  .load(JSON_FILE_PATH)


    - We can also access nested structures in the JSON document directly:

        new_df = df.withColumn("year", col("fields.year")) \
                   .withColumn("coordinates", col("geometry.coordinates"))



- Ingesting a Multiline JSON File

    - 




- Ingesting an XML File

- Ingesting a Text File

- The Problem with Traditional File Formats

- Avro

- ORC

- Parquet

- Comparing Avro, ORC, and Parquet

- Ingesting Avro

- Ingesting ORC

- Ingesting Parquet




