------------------------------------------------------------------------------
|  CHAPTER 2 - ACCELERATING LARGE DATASET WORK - MAP AND PARALLEL COMPUTING  |
------------------------------------------------------------------------------

- Introduction to Map

    - 3 primary capabilities of map

        - We can use it to replace for loops.
        - We can use it to transform data.
        - Map evaluates only when necessary, not when called.


    - The power of lazy functions (like map) for large datasets

        When moving from Python2 to Python3, the 'range' function was made lazy.  This was
          so that huge ranges could be created without:

          1. Taking the time to generate a massive list of numbers
          2. Storing all the values in memory when we may only need a few



- Parallel Processing

    - Processors and processing

        # Get number of CPUs on machine
        >>> import os
        >>> os.cpu_count()


    - Problems that may be encountered when working with parallelization in Python:

        - The inability to pickle data or functions, causing our programs to not run
        - Order-sensitive operations returning inconsistent results
        - State-dependent operations returning inconsistent results


    - Parallelization and pickling

        - When we write something like our parallel map, Python is doing a lot of work
            behind the scenes.  One of those things is pickling.

        - Pickling is Python's version of object serialization (aka marshalling), which is
            the storing of objects from our code on disk in an efficient binary format that
            can be read back at a later time.

        - It is a gotcha that some Python objects cannot be pickled, and this will cause an
            error.  All standard Python objects are pickleable, but lambda functions and 
            nested functions and classes are not.


        - If we have to try and use unpicklable objects, we can use the open source 'pathos'
            library which provides the 'dill' module, which allows us to pickle almost
            anything.

            # Install pathos
            $ pip install pathos

            # Use pathos as process pool
            from pathos.multiprocessing import ProcessPool
            ...
            with ProcessPool(nodes=4) as P:
                blog_posts = P.map(get_url,days_between((2000,1,1),(2011,1,1)))


    - Order and parallelization

        - Even though Python will execute out of order, it will still remember the order
            after execution is complete.  For instance, this will print the numbers out of
            order but will return a data structure that is in order:

            def print_and_return(x):
                print(x); return x

            with Pool() as P:
                P.map(print_and_return, range(20))



- Scraping a Wikipedia Network

    - Problem

        - We want to create a topic network graph from Wikipedia.  We want to be able to
            enter a search term and find all the pages in that page's immediate network - 
            pages that link to that page or that page links to.

        - The result will be a graph of all the pages in our network.


    - Breaking down the problem

        To-do list:

          - Write a function that gets the inbound and outbound links of a Wikipedia page.
          - Get the inbound and outbound links from our initial page.
          - Gather those pages in one long list.
          - Get the inbound and outbound links from all of those pages.
          - Weâ€™ll do this in parallel, to speed things up.
          - Represent all our links as edges between pages.
          - Bonus: Use a graphing library (like networkx) to display the graph.


    - Generating a graph with networkx

        $ pip install networkx
